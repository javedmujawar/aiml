{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5ffad6",
   "metadata": {},
   "source": [
    "# 1) Implementatoin of simple nerual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7dc7c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output probabilities:\n",
      "[[0.92098369 0.07901631]\n",
      " [0.92067044 0.07932956]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Forward pass\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "# Example usage:\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 2\n",
    "\n",
    "# Create a neural network\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Test forward pass with sample input\n",
    "X = np.array([[0.1, 0.2], [0.2, 0.3]])\n",
    "output = model.forward(X)\n",
    "print(\"Output probabilities:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c40e3",
   "metadata": {},
   "source": [
    "# 2)  Implentation of perceprotron  learning  algorithm NAND and NOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae02c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND Gate:\n",
      "[0 0] -> 1\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "\n",
      "NOR Gate:\n",
      "[0 0] -> 1\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=10):\n",
    "        self.weights = np.zeros(input_size + 1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def activation(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return self.activation(summation)\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.epochs):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "\n",
    "# Training data for NAND gate\n",
    "training_inputs_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels_nand = np.array([1, 1, 1, 0])\n",
    "\n",
    "# Training data for NOR gate\n",
    "training_inputs_nor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels_nor = np.array([1, 0, 0, 0])\n",
    "\n",
    "# Create perceptrons for NAND and NOR gates\n",
    "perceptron_nand = Perceptron(2)\n",
    "perceptron_nor = Perceptron(2)\n",
    "\n",
    "# Train the perceptrons\n",
    "perceptron_nand.train(training_inputs_nand, labels_nand)\n",
    "perceptron_nor.train(training_inputs_nor, labels_nor)\n",
    "\n",
    "# Test the perceptrons\n",
    "test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "print(\"NAND Gate:\")\n",
    "for inputs in test_inputs:\n",
    "    print(f\"{inputs} -> {perceptron_nand.predict(inputs)}\")\n",
    "\n",
    "print(\"\\nNOR Gate:\")\n",
    "for inputs in test_inputs:\n",
    "    print(f\"{inputs} -> {perceptron_nor.predict(inputs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c750fa",
   "metadata": {},
   "source": [
    "# 3)  Build an artificial neural network by implementing the backpropogation algorithm, considering few test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8aec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2675\n",
      "Epoch 1000, Loss: 0.2499\n",
      "Epoch 2000, Loss: 0.2471\n",
      "Epoch 3000, Loss: 0.2243\n",
      "Epoch 4000, Loss: 0.1792\n",
      "Epoch 5000, Loss: 0.1512\n",
      "Epoch 6000, Loss: 0.1392\n",
      "Epoch 7000, Loss: 0.0428\n",
      "Epoch 8000, Loss: 0.0125\n",
      "Epoch 9000, Loss: 0.0069\n",
      "\n",
      "Predicted Outputs:\n",
      "Input: [0 0], Predicted Output: 0.0704\n",
      "Input: [0 1], Predicted Output: 0.9146\n",
      "Input: [1 0], Predicted Output: 0.9432\n",
      "Input: [1 1], Predicted Output: 0.0586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "        self.bias_input_hidden = np.zeros((1, hidden_size))\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "        self.bias_hidden_output = np.zeros((1, output_size))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        # Sigmoid activation function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        # Derivative of sigmoid activation function\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Forward pass\n",
    "        self.hidden_layer_input = np.dot(inputs, self.weights_input_hidden) + self.bias_input_hidden\n",
    "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_hidden_output\n",
    "        self.output_layer_output = self.sigmoid(self.output_layer_input)\n",
    "        return self.output_layer_output\n",
    "    \n",
    "    def backward(self, inputs, targets, learning_rate):\n",
    "        # Backpropagation\n",
    "        # Compute error and delta for output layer\n",
    "        error = targets - self.output_layer_output\n",
    "        delta_output = error * self.sigmoid_derivative(self.output_layer_output)\n",
    "        \n",
    "        # Compute error and delta for hidden layer\n",
    "        error_hidden = np.dot(delta_output, self.weights_hidden_output.T)\n",
    "        delta_hidden = error_hidden * self.sigmoid_derivative(self.hidden_layer_output)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output += learning_rate * np.dot(self.hidden_layer_output.T, delta_output)\n",
    "        self.bias_hidden_output += learning_rate * np.sum(delta_output, axis=0, keepdims=True)\n",
    "        self.weights_input_hidden += learning_rate * np.dot(inputs.T, delta_hidden)\n",
    "        self.bias_input_hidden += learning_rate * np.sum(delta_hidden, axis=0, keepdims=True)\n",
    "    \n",
    "    def train(self, inputs, targets, learning_rate, epochs):\n",
    "        # Training the neural network\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            outputs = self.forward(inputs)\n",
    "            # Backpropagation\n",
    "            self.backward(inputs, targets, learning_rate)\n",
    "            # Compute and print loss\n",
    "            loss = np.mean(np.square(targets - outputs))\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "# Sample dataset\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "targets = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Create and train the neural network\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "nn.train(inputs, targets, learning_rate, epochs)\n",
    "\n",
    "# Test the trained model\n",
    "test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "predicted_outputs = nn.forward(test_inputs)\n",
    "print(\"\\nPredicted Outputs:\")\n",
    "for i in range(len(test_inputs)):\n",
    "    print(f\"Input: {test_inputs[i]}, Predicted Output: {predicted_outputs[i][0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902c16d",
   "metadata": {},
   "source": [
    "#  Q.4) Display  the contents of tf2_constants.py, which illustrates how to assign and print the values of some TF2 constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bb8cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jades\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jades\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of PI: 3.14159\n",
      "Value of EULER: 2.71828\n",
      "Value of ZERO: 0\n",
      "Value of ONE: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define some TensorFlow constants\n",
    "PI = tf.constant(3.14159)\n",
    "EULER = tf.constant(2.71828)\n",
    "ZERO = tf.constant(0)\n",
    "ONE = tf.constant(1)\n",
    "\n",
    "# Print the values of the constants\n",
    "print(\"Value of PI:\", PI.numpy())\n",
    "print(\"Value of EULER:\", EULER.numpy())\n",
    "print(\"Value of ZERO:\", ZERO.numpy())\n",
    "print(\"Value of ONE:\", ONE.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa4ebb1",
   "metadata": {},
   "source": [
    "# Q.5) Demonstrate how to work with string in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c148fdb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Reviews:\n",
      "b'This  movie was fantastic!'\n",
      "b'The acting was terrible!'\n",
      "b'Such a  boring plot :('\n",
      "b'Wow, amazing special effects!'\n",
      "\n",
      "Lowercase Reviews:\n",
      "b'this  movie was fantastic!'\n",
      "b'the acting was terrible!'\n",
      "b'such a  boring plot :('\n",
      "b'wow, amazing special effects!'\n",
      "\n",
      "Cleaned Reviews (Punctuation Removed):\n",
      "b'this  movie was fantastic '\n",
      "b'the acting was terrible '\n",
      "b'such a  boring plot   '\n",
      "b'wow  amazing special effects '\n",
      "\n",
      "Normalized Reviews (Extra Whitespace Removed):\n",
      "b'this movie was fantastic '\n",
      "b'the acting was terrible '\n",
      "b'such a boring plot '\n",
      "b'wow amazing special effects '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Sample movie reviews (as a list of strings)\n",
    "reviews = [\n",
    "    \"This  movie was fantastic!\",\n",
    "    \"The acting was terrible!\",\n",
    "    \"Such a  boring plot :(\",\n",
    "    \"Wow, amazing special effects!\",\n",
    "]\n",
    "\n",
    "# Convert the list to a string tensor\n",
    "reviews_tensor = tf.constant(reviews)\n",
    "\n",
    "# Print the original reviews\n",
    "print(\"Original Reviews:\")\n",
    "for review in reviews_tensor.numpy():\n",
    "  print(review)\n",
    "\n",
    "# Lowercase all reviews\n",
    "lowercase_reviews = tf.strings.lower(reviews_tensor)\n",
    "print(\"\\nLowercase Reviews:\")\n",
    "for review in lowercase_reviews.numpy():\n",
    "  print(review)\n",
    "\n",
    "# Remove punctuation (replace with spaces)\n",
    "cleaned_reviews = tf.strings.regex_replace(lowercase_reviews, r\"[^\\w\\s]\", \" \")\n",
    "print(\"\\nCleaned Reviews (Punctuation Removed):\")\n",
    "for review in cleaned_reviews.numpy():\n",
    "  print(review)\n",
    "\n",
    "# Remove extra whitespace (replace multiple spaces with single space)\n",
    "normalized_reviews = tf.strings.regex_replace(cleaned_reviews, r\"[^\\w\\s]|\\s+\", \" \")\n",
    "\n",
    "\n",
    "print(\"\\nNormalized Reviews (Extra Whitespace Removed):\")\n",
    "for review in normalized_reviews.numpy():\n",
    "  print(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d613c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94d9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec03326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da99a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9885e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
